{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\afhar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import gensim\n",
    "import spacy\n",
    "import altair as alt\n",
    "from hyphen import Hyphenator\n",
    "from gensim.parsing.preprocessing import preprocess_string, STOPWORDS \n",
    "from gensim.parsing.preprocessing import strip_tags\n",
    "from gensim.parsing.preprocessing import strip_punctuation\n",
    "from gensim.parsing.preprocessing import strip_multiple_whitespaces\n",
    "from gensim.parsing.preprocessing import stem_text\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from gensim.parsing.preprocessing import strip_numeric\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from sklearn.metrics import accuracy_score\n",
    "import textstat\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "cwd = os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>230059</th>\n",
       "      <td>Dixon sang bass for The Jubilee Singers , a lo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190204</th>\n",
       "      <td>The majority view today is that Mark is the fi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167093</th>\n",
       "      <td>Early life Barry George was born in Hammersmit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397703</th>\n",
       "      <td>The major interests of the AIEE were wire comm...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222293</th>\n",
       "      <td>The book was the first systematic discussion o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7637</th>\n",
       "      <td>New York City Police Museum site Accessed Janu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230498</th>\n",
       "      <td>For the Egyptian Book of the Dead , click here .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137610</th>\n",
       "      <td>A graveyard with the statue of the Commendatore .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391519</th>\n",
       "      <td>It was made by the American game maker Bethesd...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213403</th>\n",
       "      <td>In January and February of 1418 , he was paid ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            original_text  label\n",
       "230059  Dixon sang bass for The Jubilee Singers , a lo...      0\n",
       "190204  The majority view today is that Mark is the fi...      1\n",
       "167093  Early life Barry George was born in Hammersmit...      1\n",
       "397703  The major interests of the AIEE were wire comm...      0\n",
       "222293  The book was the first systematic discussion o...      0\n",
       "7637    New York City Police Museum site Accessed Janu...      1\n",
       "230498   For the Egyptian Book of the Dead , click here .      0\n",
       "137610  A graveyard with the statue of the Commendatore .      1\n",
       "391519  It was made by the American game maker Bethesd...      0\n",
       "213403  In January and February of 1418 , he was paid ...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import  data\n",
    "data_dir = cwd + '\\\\data\\\\'\n",
    "df_train_raw = pd.read_csv(data_dir+'WikiLarge_Train.csv')\n",
    "df_test_raw = pd.read_csv(data_dir+'WikiLarge_Test.csv')\n",
    "df_train_raw.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data processing\n",
    "#df_train_raw['tokens'] = df_train_raw['original_text'].apply(lambda x: text_process(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tokenize_text(df):\n",
    "    \"\"\"\n",
    "    tokenize the text from the articles\n",
    "    \"\"\"\n",
    "    df['original_text'] = df['original_text'].astype(str)\n",
    "    # YOUR CODE HERE\n",
    "    custom_filter = [strip_tags,strip_multiple_whitespaces,\n",
    "                    strip_punctuation]\n",
    "    df['tokens'] = df['original_text'].apply(lambda x:preprocess_string(x, custom_filter))\n",
    "    return df\n",
    "def pos_tag(tok_list):\n",
    "    return nltk.pos_tag(tok_list)\n",
    "def counters(row):\n",
    "    \"\"\"\n",
    "    This includes all the counting operations on the tokens\n",
    "    \"\"\"\n",
    "    #part of speech counting\n",
    "    pos_l = row['pos']\n",
    "    nouns = 0\n",
    "    verbs = 0\n",
    "    Pnouns = 0\n",
    "    adjectives = 0\n",
    "    adverbs = 0\n",
    "    for pair in pos_l:\n",
    "        if pair[1][0] == 'N':\n",
    "            nouns+=1\n",
    "        if pair[1][0] == 'V':\n",
    "            verbs+=1\n",
    "        if pair[1] == 'NNP':\n",
    "            Pnouns+=1\n",
    "        if pair[1] == 'NNPS':\n",
    "            Pnouns+=1\n",
    "        if pair[1][0] == 'J':\n",
    "            adjectives+=1\n",
    "        if pair[1][0] == 'R':\n",
    "            adverbs+=1 \n",
    "    row['nouns'] = nouns \n",
    "    row['verbs'] = verbs \n",
    "    row['Pnouns'] = Pnouns \n",
    "    row['adjectives'] = adjectives \n",
    "    row['adverbs'] = adverbs \n",
    "    \n",
    "    #number of words\n",
    "    row['num_words'] = len(row['tokens'])\n",
    "    \n",
    "    #number of sylables\n",
    "    syls = []\n",
    "    h = Hyphenator('en_US')\n",
    "    tok_l = row['tokens']\n",
    "    for t in tok_l:\n",
    "        syls.append(len(h.syllables(t))+1)\n",
    "    syls = np.array(syls)\n",
    "    row['syls'] = syls\n",
    "    try:\n",
    "        row['max_syls'] = np.max(syls)\n",
    "        row['avg_syls'] = np.mean(syls)\n",
    "        row['std_syls'] = np.std(syls)\n",
    "    except:\n",
    "        row['max_syls'] = np.nan\n",
    "        row['avg_syls'] = np.nan\n",
    "        row['std_syls'] = np.nan\n",
    "    return row\n",
    "def readability_scores(row):\n",
    "    #https://pypi.org/project/textstat/\n",
    "    text = row['original_text']\n",
    "    row['flesch_score'] = textstat.flesch_reading_ease(text)\n",
    "    row['flesch_grade_lvl'] = textstat.flesch_kincaid_grade(text)\n",
    "    row['fog_grade_lvl'] = textstat.gunning_fog(text)\n",
    "    row['ARI_grade'] = textstat.automated_readability_index(text)\n",
    "    row['CLI_grade'] = textstat.coleman_liau_index(text)\n",
    "    row['LWF_grade'] = textstat.linsear_write_formula(text)\n",
    "    row['Dale-Chall_score'] = textstat.dale_chall_readability_score(text)\n",
    "    row['combined_grade'] = textstat.text_standard(text, float_output=False)\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The \"do stuff block\"\n",
    "#training data\n",
    "df_train_raw = df_train_raw #for teppsting, lets work with a small set\n",
    "df_tokenized = clean_tokenize_text(df_train_raw)\n",
    "df_tokenized['pos'] = df_tokenized['tokens'].apply(lambda x: pos_tag(x))\n",
    "df_tokenized = df_tokenized.apply(lambda row:counters(row), axis =1)\n",
    "df_tokenized = df_tokenized.apply(lambda row:readability_scores(row), axis =1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    503\n",
       "1    497\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_tokenized[df_tokenized['label']==0]\n",
    "df_train_raw = df_train_raw.sample(1000,random_state = 10)\n",
    "df_train_raw ['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tokenized.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep2 = pd.read_pickle('brosko_train_f.pkl')\n",
    "merged = df_tokenized.merge(prep2, left_index=True, right_index=True, how='inner')\n",
    "#merged.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['original_text_x', 'label_x', 'tokens', 'pos', 'nouns', 'verbs',\n",
       "       'Pnouns', 'adjectives', 'adverbs', 'num_words', 'syls', 'max_syls',\n",
       "       'avg_syls', 'std_syls', 'flesch_score', 'flesch_grade_lvl',\n",
       "       'fog_grade_lvl', 'ARI_grade', 'CLI_grade', 'LWF_grade',\n",
       "       'Dale-Chall_score', 'combined_grade', 'index', 'original_text_y',\n",
       "       'label_y', 'clean_text', 'word_count', 'clean_text_no_stop',\n",
       "       'word_count_no_stop', 'Nsyll', 'AoA_Kup_lem', 'Perc_known_lem'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = merged[['nouns', 'verbs',\n",
    "       'Pnouns', 'adjectives', 'adverbs', 'num_words', 'max_syls',\n",
    "       'avg_syls', 'std_syls', 'flesch_score', 'flesch_grade_lvl',\n",
    "       'fog_grade_lvl', 'ARI_grade', 'CLI_grade', 'LWF_grade',\n",
    "       'Dale-Chall_score','word_count_no_stop','Nsyll','AoA_Kup_lem','Perc_known_lem']]\n",
    "#X_train = merged[['flesch_score', 'flesch_grade_lvl',\n",
    "#       'fog_grade_lvl', 'ARI_grade', 'CLI_grade', 'LWF_grade',\n",
    "#       'Dale-Chall_score']]\n",
    "X_train = X_train.replace(np.nan, 0)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "y_train = merged['label_x'].values\n",
    "#y_train =y_train.reshape(len(y_train),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= X_train\n",
    "y = y_train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.672707597512285"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 700) #start with square root of N, to add a loop later\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_train)\n",
    "accuracy_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6829656666715139"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth = 16, max_features = None)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6552416129829715"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6485305451742842"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tokenized.to_pickle('df_tokenized.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The \"do stuff block\"\n",
    "#test data\n",
    "df_test_raw = df_test_raw #for teppsting, lets work with a small set\n",
    "df_tokenized_test = clean_tokenize_text(df_test_raw)\n",
    "df_tokenized_test['pos'] = df_tokenized_test['tokens'].apply(lambda x: pos_tag(x))\n",
    "df_tokenized_test = df_tokenized_test.apply(lambda row:counters(row), axis =1)\n",
    "df_tokenized_test = df_tokenized_test.apply(lambda row:readability_scores(row), axis =1)\n",
    "prep3 = pd.read_pickle('brosko_test_f.pkl')\n",
    "merged_test = df_tokenized_test.merge(prep3, left_index=True, right_index=True, how='inner')\n",
    "X_test = merged_test[['flesch_score', 'flesch_grade_lvl',\n",
    "       'fog_grade_lvl', 'ARI_grade', 'CLI_grade', 'LWF_grade',\n",
    "       'Dale-Chall_score']]\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_test.to_pickle('test_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = merged_test[['nouns', 'verbs',\n",
    "       'Pnouns', 'adjectives', 'adverbs', 'num_words', 'max_syls',\n",
    "       'avg_syls', 'std_syls', 'flesch_score', 'flesch_grade_lvl',\n",
    "       'fog_grade_lvl', 'ARI_grade', 'CLI_grade', 'LWF_grade',\n",
    "       'Dale-Chall_score','word_count_no_stop','Nsyll','AoA_Kup_lem','Perc_known_lem']]\n",
    "X_test = X_test.replace(np.nan, 0)\n",
    "X_test = scaler.transform(X_test)\n",
    "y_pred = knn.predict(X_test)\n",
    "df = pd.DataFrame()\n",
    "df['id'] =merged_test.index\n",
    "df['label'] = y_pred\n",
    "df.to_csv('knn_textscores_only.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.53804494, -1.3207071 , -1.01237818, ..., -3.20056336,\n",
       "        -3.82082126, -6.33106802],\n",
       "       [-1.53804494, -1.3207071 , -1.01237818, ..., -3.20056336,\n",
       "        -3.82082126, -6.33106802],\n",
       "       [-1.53804494, -1.3207071 , -1.01237818, ..., -3.20056336,\n",
       "        -3.82082126, -6.33106802],\n",
       "       ...,\n",
       "       [-1.34765019, -1.3207071 , -1.01237818, ..., -1.57604297,\n",
       "        -1.82603962,  0.21604896],\n",
       "       [-1.34765019, -1.3207071 , -1.01237818, ..., -1.57604297,\n",
       "        -1.82603962,  0.21604896],\n",
       "       [-1.34765019, -1.3207071 , -1.01237818, ..., -1.57604297,\n",
       "        -1.82603962,  0.21604896]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
